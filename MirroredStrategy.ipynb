{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0\n",
      "Eager mode:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAST GPU causes an error: \"/gpu:7\" , thus, defective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\", \"/gpu:3\",\"/gpu:4\", \"/gpu:5\", \"/gpu:6\"])\n",
    "# with strategy.scope():\n",
    "#   inputs = tf.keras.layers.Input(shape=(1,))\n",
    "#   predictions = tf.keras.layers.Dense(1)(inputs)\n",
    "#   model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n",
    "#   model.compile(loss='mse',\n",
    "#                 optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\", \"/gpu:3\",\"/gpu:4\", \"/gpu:5\", \"/gpu:6\"])\n",
    "\n",
    "def get_data():\n",
    "  datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "  mnist_train, mnist_test = datasets['train'], datasets['test']\n",
    "\n",
    "  BUFFER_SIZE = 10000\n",
    "\n",
    "  BATCH_SIZE_PER_REPLICA = 64\n",
    "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync\n",
    "\n",
    "  def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "\n",
    "    return image, label\n",
    "\n",
    "  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n",
    "\n",
    "  return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# def plot(history):\n",
    "#     plt.plot(history.history['accuracy'])\n",
    "#     plt.plot(history.history['val_accuracy'])\n",
    "#     plt.title('model accuracy')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'validation'], loc='upper left')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(train_dataset, eval_dataset, epochs):\n",
    "    with mirrored_strategy.scope():\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(model,to_file='model.png',show_shapes=True, show_layer_names=True)\n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(train_dataset, epochs=epochs, validation_data=eval_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelInterleaveDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelInterleaveDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                346176    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 347,146\n",
      "Trainable params: 347,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op __inference_initialize_variables_16662 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op __inference_distributed_function_19573 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "    134/Unknown - 15s 108ms/step - loss: 0.4231 - accuracy: 0.8894Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op __inference_distributed_function_21235 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "134/134 [==============================] - 18s 134ms/step - loss: 0.4231 - accuracy: 0.8894 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 0.1291 - accuracy: 0.9646 - val_loss: 0.0871 - val_accuracy: 0.9743\n",
      "Epoch 3/20\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0846 - accuracy: 0.9770 - val_loss: 0.0725 - val_accuracy: 0.9774\n",
      "Epoch 4/20\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 0.0659 - accuracy: 0.9819 - val_loss: 0.0575 - val_accuracy: 0.9821\n",
      "Epoch 5/20\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0544 - accuracy: 0.9849 - val_loss: 0.0567 - val_accuracy: 0.9802\n",
      "Epoch 6/20\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0461 - accuracy: 0.9868 - val_loss: 0.0547 - val_accuracy: 0.9806\n",
      "Epoch 7/20\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.0455 - val_accuracy: 0.9849\n",
      "Epoch 8/20\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0365 - accuracy: 0.9894 - val_loss: 0.0476 - val_accuracy: 0.9843\n",
      "Epoch 9/20\n",
      "134/134 [==============================] - 3s 25ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 0.0435 - val_accuracy: 0.9850\n",
      "Epoch 10/20\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0472 - val_accuracy: 0.9839\n",
      "Epoch 11/20\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.0545 - val_accuracy: 0.9820\n",
      "Epoch 12/20\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.0516 - val_accuracy: 0.9837\n",
      "Epoch 13/20\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0438 - val_accuracy: 0.9849\n",
      "Epoch 14/20\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 0.0481 - val_accuracy: 0.9844\n",
      "Epoch 15/20\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0159 - accuracy: 0.9961 - val_loss: 0.0462 - val_accuracy: 0.9859\n",
      "Epoch 16/20\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0441 - val_accuracy: 0.9854\n",
      "Epoch 17/20\n",
      "134/134 [==============================] - 3s 24ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0477 - val_accuracy: 0.9848\n",
      "Epoch 18/20\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0473 - val_accuracy: 0.9848\n",
      "Epoch 19/20\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.0458 - val_accuracy: 0.9855\n",
      "Epoch 20/20\n",
      "134/134 [==============================] - 4s 27ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0498 - val_accuracy: 0.9848\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:6\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:5\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:4\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:3\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00:01:29'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, eval_dataset = get_data()\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "run_model(train_dataset, eval_dataset, epochs)\n",
    "elapsed_time = time.time() - start_time\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "#print(\"elapsed time = {}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(retina=True, filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
